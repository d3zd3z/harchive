There is a lot to be put here.  This is a prototype.

Important tasks:

- Pool recovery.  Be able to recover the index from just the pool
  files themselves.  This keeps us from needing to archive the index
  file.  It will also be possible to skip corrupted data this way, and
  have some kind of recoverable backup.

- Partial recovery.  If the pool is corrupt, don't just stop the
  backup, try as much as possible to continue.

- Dump and restore the permissions on the root directory of the
  backup.

Smaller tasks:

- Profiling.  'hfile' is a bit hungrier than it seems like it should
  be.

- Do the strange tricks necessary to get the permissions right on
  symlinks.  Symlinks under linux are created with 777(octal)
  permissions with the current umask bits cleared.  We can restore a
  symlink properly by setting the umask appropriately, creating the
  symlink, and then putting the umask back.

- Have aggressive discussion/flamewar about restoring named pipes and
  sockets.  When the program owning a socket exits, the socket's only
  real purpose is to hold permissions.  It isn't really meaningful
  without something attached to it.  It isn't possible to open a unix
  socket without creating the socket file.  Named pipes could be
  necessary to recreate, since they have meaningful semantics on a new
  filesystem.  I don't believe they are heavily used, though.

- Restore sparse files properly.  Two approaches are to always scan
  for holes in files (which would slow down restore), or somehow
  detect that a file is sparse.

partial: Don't use the default instances for Binary to get more efficient
  encoding of cache data and directories.  Since caches are stored in
  the index, making these smaller can help.

- Figure out how to determine page and cache sizes for the Sqlite3
  database.  It is probably going to be better to have more memory
  dedicated to the database cache than to thrash I/O more.

- Figure out how to make the exclusion database more than just
  hardcoded paths in the source.

DONE Allow non-root restores that gracefully allow chown to fail.

- Make regular restore a bit more aggressive about not overwriting
  anything.  Need to use Posix file open to get these semantics.

- Have a table just listing the backup id's to avoid a long search
  through the blob table.  It is wasteful to make an index on the
  'kind' field of blobs since most will be redundant anyway.

- Order and constrain the catalog.  At least put an order-by in the
  query so the records come out in a predictable order.

- Print status during the restore to keep from getting bored.

- Do we need to track hardlinks on backup?  It wouldn't affect space
  and would only be an issue if someone has multiple hardlinks of very
  large files.  Tracking this would save the time of running sha1
  hashes on each link of the file.

Bigger tasks:

- Scheduling and automation.

- Fuse support.  Should be able to make every backup ever performed in
  a pool visible.  Ultimate in pick and chose restore.

- Management of tertiary storage on tape or DVD/CD.

- Data retirement and garbage collection.  This might be considered a
  bad idea from a backup point of view.  Migrating current directories
  to a new pool would be useful, although just backing up the data
  again would probably be just about as fast, and possibly faster if
  it is two machines doing it.
